"""
Drug Response Prediction - 5-Fold Cross Validation Pipeline
============================================================

This module provides a complete training and evaluation workflow for drug response
prediction models. It handles multiple cross-validation strategies as specified in
the project requirements.

Compatible with TF-IDF drug features from drug_smiles_tfidf.py

Author: Your Team
Date: December 2025
"""

import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from typing import Tuple, List, Callable, Optional
from dataclasses import dataclass
import json
import pickle


# ============================================================================
# DATA LOADING UTILITIES
# ============================================================================

def load_drug_features_from_csv(csv_path: str) -> Tuple[np.ndarray, dict, dict]:
    """
    Load drug TF-IDF features from CSV file generated by drug_smiles_tfidf.py

    Args:
        csv_path: Path to drug_smiles_tfidf_features.csv

    Returns:
        drug_features: Array of shape [n_drugs, tfidf_dim]
        drug_name_to_idx: Dictionary mapping drug_name -> index
        cid_to_idx: Dictionary mapping CID (str) -> index
    """
    import pandas as pd

    df = pd.read_csv(csv_path)

    # Extract metadata columns
    drug_names = df['drug_name'].values
    cids = df['CID'].astype(str).values

    # Extract TF-IDF feature columns (skip first 3 metadata columns)
    feature_cols = df.columns[3:]  # Skip drug_name, CID, StandardizedSMILES
    drug_features = df[feature_cols].values

    # Create index mappings
    drug_name_to_idx = {name: idx for idx, name in enumerate(drug_names)}
    cid_to_idx = {cid: idx for idx, cid in enumerate(cids)}

    print(f"✓ Loaded {len(drug_features)} drugs with {drug_features.shape[1]} TF-IDF features")
    print(f"  Feature columns: {len(feature_cols)}")

    return drug_features, drug_name_to_idx, cid_to_idx


def load_drug_features_from_json(json_path: str) -> Tuple[np.ndarray, dict]:
    """
    Load drug TF-IDF features from JSON file generated by drug_smiles_tfidf.py

    Args:
        json_path: Path to drug_smiles_tfidf_vectors.json

    Returns:
        drug_features: Array of shape [n_drugs, tfidf_dim]
        drug_name_to_idx: Dictionary mapping drug_name -> index
    """
    with open(json_path, 'r') as f:
        data = json.load(f)

    # First record contains feature names
    feature_names = data[0]["feature_names"]
    print(f"TF-IDF feature dimension: {len(feature_names)}")

    # Rest are drug records
    drug_records = data[1:]
    drug_features = []
    drug_name_to_idx = {}

    for idx, record in enumerate(drug_records):
        drug_name = record["drug_name"]
        tfidf_vector = np.array(record["tfidf_vector"])
        drug_features.append(tfidf_vector)
        drug_name_to_idx[drug_name] = idx

    drug_features = np.array(drug_features)
    print(f"✓ Loaded {len(drug_features)} drugs with {drug_features.shape[1]} features")

    return drug_features, drug_name_to_idx


def load_drug_features_from_pkl(pkl_path: str) -> Tuple[np.ndarray, dict]:
    """
    Load drug TF-IDF vectorizer from pickle file.
    Note: This loads the vectorizer, not the features directly.
    Use load_drug_features_from_json() for pre-computed features.

    Args:
        pkl_path: Path to drug_smiles_tfidf_vectorizer.pkl

    Returns:
        Vectorizer object (for reference or re-transforming)
    """
    with open(pkl_path, 'rb') as f:
        vectorizer = pickle.load(f)
    print(f"✓ Loaded TF-IDF vectorizer with {len(vectorizer.get_feature_names_out())} features")
    return vectorizer


# ============================================================================
# DATA STRUCTURE
# ============================================================================

@dataclass
class DrugResponseData:
    """Container for all drug response data.

    Attributes:
        cell_features: Array of shape [n_cells, cell_feat_dim]
        drug_features: Array of shape [n_drugs, drug_feat_dim]
        pair_cell_idx: Array of length N_pairs, values in [0, n_cells-1]
        pair_drug_idx: Array of length N_pairs, values in [0, n_drugs-1]
        pair_ic50: Array of length N_pairs (Log IC50 targets)
    """
    cell_features: np.ndarray
    drug_features: np.ndarray
    pair_cell_idx: np.ndarray
    pair_drug_idx: np.ndarray
    pair_ic50: np.ndarray

    def validate(self):
        """Basic validation of data consistency."""
        n_pairs = len(self.pair_ic50)
        assert len(self.pair_cell_idx) == n_pairs, "Cell idx length mismatch"
        assert len(self.pair_drug_idx) == n_pairs, "Drug idx length mismatch"
        assert self.pair_cell_idx.max() < len(self.cell_features), "Invalid cell idx"
        assert self.pair_drug_idx.max() < len(self.drug_features), "Invalid drug idx"
        print(f"✓ Data validated: {n_pairs} pairs, {len(self.cell_features)} cells, {len(self.drug_features)} drugs")
        print(f"  Cell features: {self.cell_features.shape}")
        print(f"  Drug features: {self.drug_features.shape}")


# ============================================================================
# DATASET
# ============================================================================

class PairDataset(Dataset):
    """Dataset for cell-drug pairs."""

    def __init__(self, pair_indices: np.ndarray, data: DrugResponseData):
        self.pair_indices = pair_indices
        self.data = data

    def __len__(self):
        return len(self.pair_indices)

    def __getitem__(self, i):
        p = self.pair_indices[i]
        c = self.data.pair_cell_idx[p]
        d = self.data.pair_drug_idx[p]

        x_cell = torch.FloatTensor(self.data.cell_features[c])
        x_drug = torch.FloatTensor(self.data.drug_features[d])
        y = torch.FloatTensor([self.data.pair_ic50[p]])

        return x_cell, x_drug, y


# ============================================================================
# CROSS-VALIDATION SPLITS
# ============================================================================

def make_random_pair_folds(data: DrugResponseData, n_folds: int = 5,
                           val_fraction: float = 0.1, seed: int = 0) -> List[Tuple]:
    """Standard random 5-fold CV on pairs.

    Returns:
        List of (train_idx, val_idx, test_idx) tuples, one per fold.
    """
    rng = np.random.RandomState(seed)
    n_pairs = len(data.pair_ic50)
    all_idx = np.arange(n_pairs)
    rng.shuffle(all_idx)
    folds = np.array_split(all_idx, n_folds)

    fold_splits = []
    for k in range(n_folds):
        test_idx = folds[k]
        train_all = np.concatenate([folds[i] for i in range(n_folds) if i != k])

        # Carve out validation set
        rng.shuffle(train_all)
        n_val = int(len(train_all) * val_fraction)
        val_idx = train_all[:n_val]
        train_idx = train_all[n_val:]

        fold_splits.append((train_idx, val_idx, test_idx))

    print(f"✓ Random split: {n_folds} folds created")
    return fold_splits


def make_cell_blind_folds(data: DrugResponseData, n_folds: int = 5,
                          val_fraction: float = 0.1, seed: int = 0) -> List[Tuple]:
    """Cell-blind CV: test on unseen cell lines.

    Returns:
        List of (train_idx, val_idx, test_idx) tuples, one per fold.
    """
    rng = np.random.RandomState(seed)
    unique_cells = np.unique(data.pair_cell_idx)
    rng.shuffle(unique_cells)
    cell_folds = np.array_split(unique_cells, n_folds)

    fold_splits = []
    for k in range(n_folds):
        test_cells = set(cell_folds[k])
        test_mask = np.isin(data.pair_cell_idx, list(test_cells))
        test_idx = np.where(test_mask)[0]
        train_idx_all = np.where(~test_mask)[0]

        rng.shuffle(train_idx_all)
        n_val = int(len(train_idx_all) * val_fraction)
        val_idx = train_idx_all[:n_val]
        train_idx = train_idx_all[n_val:]

        fold_splits.append((train_idx, val_idx, test_idx))

    print(f"✓ Cell-blind split: {n_folds} folds created")
    return fold_splits


def make_drug_blind_folds(data: DrugResponseData, n_folds: int = 5,
                          val_fraction: float = 0.1, seed: int = 0) -> List[Tuple]:
    """Drug-blind CV: test on unseen drugs.

    Returns:
        List of (train_idx, val_idx, test_idx) tuples, one per fold.
    """
    rng = np.random.RandomState(seed)
    unique_drugs = np.unique(data.pair_drug_idx)
    rng.shuffle(unique_drugs)
    drug_folds = np.array_split(unique_drugs, n_folds)

    fold_splits = []
    for k in range(n_folds):
        test_drugs = set(drug_folds[k])
        test_mask = np.isin(data.pair_drug_idx, list(test_drugs))
        test_idx = np.where(test_mask)[0]
        train_idx_all = np.where(~test_mask)[0]

        rng.shuffle(train_idx_all)
        n_val = int(len(train_idx_all) * val_fraction)
        val_idx = train_idx_all[:n_val]
        train_idx = train_idx_all[n_val:]

        fold_splits.append((train_idx, val_idx, test_idx))

    print(f"✓ Drug-blind split: {n_folds} folds created")
    return fold_splits


def make_cell_drug_blind_folds(data: DrugResponseData, n_folds: int = 5,
                               val_fraction: float = 0.1, seed: int = 0) -> List[Tuple]:
    """Strict cell+drug blind CV: test on pairs with both unseen cell AND unseen drug.

    Train: pairs where cell NOT in test_cells AND drug NOT in test_drugs
    Test: pairs where cell IN test_cells AND drug IN test_drugs

    Returns:
        List of (train_idx, val_idx, test_idx) tuples, one per fold.
    """
    rng = np.random.RandomState(seed)
    unique_cells = np.unique(data.pair_cell_idx)
    unique_drugs = np.unique(data.pair_drug_idx)
    rng.shuffle(unique_cells)
    rng.shuffle(unique_drugs)

    cell_folds = np.array_split(unique_cells, n_folds)
    drug_folds = np.array_split(unique_drugs, n_folds)

    fold_splits = []
    for k in range(n_folds):
        test_cells = set(cell_folds[k])
        test_drugs = set(drug_folds[k])

        # Test: both cell AND drug in test sets
        test_mask = (np.isin(data.pair_cell_idx, list(test_cells)) &
                    np.isin(data.pair_drug_idx, list(test_drugs)))

        # Train: neither cell NOR drug in test sets
        train_mask = (~np.isin(data.pair_cell_idx, list(test_cells)) &
                     ~np.isin(data.pair_drug_idx, list(test_drugs)))

        test_idx = np.where(test_mask)[0]
        train_idx_all = np.where(train_mask)[0]

        rng.shuffle(train_idx_all)
        n_val = int(len(train_idx_all) * val_fraction)
        val_idx = train_idx_all[:n_val]
        train_idx = train_idx_all[n_val:]

        fold_splits.append((train_idx, val_idx, test_idx))

    print(f"✓ Cell+Drug blind split: {n_folds} folds created")
    return fold_splits


# ============================================================================
# TRAINING & EVALUATION
# ============================================================================

def train_one_fold(model_class: type,
                   data: DrugResponseData,
                   train_idx: np.ndarray,
                   val_idx: np.ndarray,
                   test_idx: np.ndarray,
                   batch_size: int = 128,
                   lr: float = 1e-3,
                   n_epochs: int = 50,
                   device: str = "cuda",
                   verbose: bool = True) -> Tuple[float, float, float]:
    """Train and evaluate a model on one fold.

    Args:
        model_class: PyTorch model class with signature:
                    __init__(cell_feat_dim, drug_feat_dim)
                    forward(x_cell, x_drug) -> y_pred
        data: DrugResponseData object
        train_idx, val_idx, test_idx: Index arrays for split
        batch_size: Batch size for training
        lr: Learning rate
        n_epochs: Number of training epochs
        device: 'cuda' or 'cpu'
        verbose: Print training progress

    Returns:
        (mse, mae, rmse) on test set
    """
    # Create datasets
    train_dataset = PairDataset(train_idx, data)
    val_dataset = PairDataset(val_idx, data)
    test_dataset = PairDataset(test_idx, data)

    # Create dataloaders
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    # Initialize model
    cell_dim = data.cell_features.shape[1]
    drug_dim = data.drug_features.shape[1]
    model = model_class(cell_dim, drug_dim).to(device)

    # Loss and optimizer
    criterion = torch.nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    # Training loop with early stopping
    best_val = float("inf")
    best_state = None

    for epoch in range(n_epochs):
        # Training
        model.train()
        train_loss = 0.0
        for x_cell, x_drug, y in train_loader:
            x_cell = x_cell.to(device)
            x_drug = x_drug.to(device)
            y = y.to(device)

            optimizer.zero_grad()
            y_pred = model(x_cell, x_drug)
            loss = criterion(y_pred, y)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * len(y)

        train_loss /= len(train_dataset)

        # Validation
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for x_cell, x_drug, y in val_loader:
                x_cell = x_cell.to(device)
                x_drug = x_drug.to(device)
                y = y.to(device)
                y_pred = model(x_cell, x_drug)
                loss = criterion(y_pred, y)
                val_loss += loss.item() * len(y)

        val_loss /= len(val_dataset)

        # Save best model
        if val_loss < best_val:
            best_val = val_loss
            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}

        if verbose and (epoch + 1) % 10 == 0:
            print(f"  Epoch {epoch+1}/{n_epochs}: Train={train_loss:.4f}, Val={val_loss:.4f}")

    # Load best model for testing
    model.load_state_dict(best_state)

    # Test evaluation
    model.eval()
    all_y_true, all_y_pred = [], []
    with torch.no_grad():
        for x_cell, x_drug, y in test_loader:
            x_cell = x_cell.to(device)
            x_drug = x_drug.to(device)
            y_pred = model(x_cell, x_drug).cpu()
            all_y_true.append(y)
            all_y_pred.append(y_pred)

    y_true = torch.cat(all_y_true).numpy()
    y_pred = torch.cat(all_y_pred).numpy()

    # Compute metrics
    mse = ((y_true - y_pred) ** 2).mean()
    mae = np.abs(y_true - y_pred).mean()
    rmse = np.sqrt(mse)

    return mse, mae, rmse


def run_cv(config_name: str,
           split_fn: Callable,
           model_class: type,
           data: DrugResponseData,
           n_folds: int = 5,
           **train_kwargs) -> np.ndarray:
    """Run complete cross-validation for one configuration.

    Args:
        config_name: Name for logging (e.g., "random", "cell_blind")
        split_fn: Function that returns list of (train, val, test) index tuples
        model_class: PyTorch model class
        data: DrugResponseData object
        n_folds: Number of folds
        **train_kwargs: Additional arguments passed to train_one_fold

    Returns:
        Array of shape [n_folds, 3] with (MSE, MAE, RMSE) for each fold
    """
    print(f"\n{'='*60}")
    print(f"Running {config_name.upper()} Cross-Validation")
    print(f"{'='*60}")

    fold_splits = split_fn(data, n_folds=n_folds)

    all_metrics = []
    for k, (train_idx, val_idx, test_idx) in enumerate(fold_splits):
        print(f"\nFold {k+1}/{n_folds}:")
        print(f"  Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}")

        mse, mae, rmse = train_one_fold(
            model_class, data, train_idx, val_idx, test_idx, **train_kwargs
        )

        all_metrics.append((mse, mae, rmse))
        print(f"  Results: MSE={mse:.4f}, MAE={mae:.4f}, RMSE={rmse:.4f}")

    # Summary statistics
    all_metrics = np.array(all_metrics)
    mean = all_metrics.mean(axis=0)
    std = all_metrics.std(axis=0)

    print(f"\n{config_name.upper()} SUMMARY (mean ± std):")
    print(f"  MSE:  {mean[0]:.4f} ± {std[0]:.4f}")
    print(f"  MAE:  {mean[1]:.4f} ± {std[1]:.4f}")
    print(f"  RMSE: {mean[2]:.4f} ± {std[2]:.4f}")

    return all_metrics


# ============================================================================
# MAIN INTERFACE
# ============================================================================

def run_all_cv(model_class: type,
               data: DrugResponseData,
               split_types: List[str] = None,
               n_folds: int = 5,
               **train_kwargs) -> dict:
    """Run all cross-validation configurations.

    Args:
        model_class: PyTorch model class
        data: DrugResponseData object
        split_types: List of split types to run. Options:
                    ["random", "cell_blind", "drug_blind", "cell_drug_blind"]
                    Default: all four
        n_folds: Number of folds (default: 5)
        **train_kwargs: Additional training arguments (batch_size, lr, n_epochs, etc.)

    Returns:
        Dictionary mapping split_type -> metrics array [n_folds, 3]
    """
    if split_types is None:
        split_types = ["random", "cell_blind", "drug_blind", "cell_drug_blind"]

    # Validate data
    data.validate()

    # Map split names to functions
    split_functions = {
        "random": make_random_pair_folds,
        "cell_blind": make_cell_blind_folds,
        "drug_blind": make_drug_blind_folds,
        "cell_drug_blind": make_cell_drug_blind_folds,
    }

    results = {}
    for split_type in split_types:
        if split_type not in split_functions:
            print(f"Warning: Unknown split type '{split_type}', skipping...")
            continue

        metrics = run_cv(
            config_name=split_type,
            split_fn=split_functions[split_type],
            model_class=model_class,
            data=data,
            n_folds=n_folds,
            **train_kwargs
        )
        results[split_type] = metrics

    return results


# ============================================================================
# EXAMPLE USAGE
# ============================================================================

if __name__ == "__main__":
    # Import model adapters (if available)
    try:
        from model_adapter import SimpleDrugResponseModel, DrugResponseModel, DEFAULT_CONFIG
        ModelClass = SimpleDrugResponseModel
        print("Using SimpleDrugResponseModel from model_adapter.py")
    except ImportError:
        # Fallback to inline model definition
        print("model_adapter.py not found, using inline SimpleModel")
        class SimpleModel(torch.nn.Module):
            def __init__(self, cell_dim, drug_dim):
                super().__init__()
                self.cell_fc = torch.nn.Linear(cell_dim, 128)
                self.drug_fc = torch.nn.Linear(drug_dim, 128)
                self.fc = torch.nn.Sequential(
                    torch.nn.Linear(256, 128),
                    torch.nn.ReLU(),
                    torch.nn.Dropout(0.3),
                    torch.nn.Linear(128, 1)
                )

            def forward(self, x_cell, x_drug):
                cell_emb = torch.relu(self.cell_fc(x_cell))
                drug_emb = torch.relu(self.drug_fc(x_drug))
                combined = torch.cat([cell_emb, drug_emb], dim=1)
                return self.fc(combined)

        ModelClass = SimpleModel

    # Example: Load drug features from TF-IDF CSV (recommended)
    print("Loading drug features from TF-IDF CSV...")
    drug_features, drug_name_to_idx, cid_to_idx = load_drug_features_from_csv(
        "drug_smiles_tfidf_features.csv"
    )

    # Alternative: Load from JSON
    # drug_features, drug_name_to_idx = load_drug_features_from_json(
    #     "drug_smiles_tfidf_vectors.json"
    # )

    # Example: Create mock cell features and pair data
    print("\nCreating example data...")
    np.random.seed(42)
    n_cells = 100
    n_drugs = len(drug_features)
    n_pairs = 1000

    # Mock cell features (your team will provide actual features)
    cell_features = np.random.randn(n_cells, 200)

    # Create random pairs
    pair_cell_idx = np.random.randint(0, n_cells, n_pairs)
    pair_drug_idx = np.random.randint(0, n_drugs, n_pairs)
    pair_ic50 = np.random.randn(n_pairs)

    data = DrugResponseData(
        cell_features=cell_features,
        drug_features=drug_features,
        pair_cell_idx=pair_cell_idx,
        pair_drug_idx=pair_drug_idx,
        pair_ic50=pair_ic50
    )

    # Run all CV configurations
    print("\nRunning cross-validation experiments...")
    results = run_all_cv(
        model_class=ModelClass,
        data=data,
        split_types=["random", "cell_blind"],  # Start with these two
        n_folds=5,
        batch_size=64,
        lr=1e-3,
        n_epochs=20,
        device="cuda" if torch.cuda.is_available() else "cpu",
        verbose=False
    )

    print("\n" + "="*60)
    print("FINAL RESULTS")
    print("="*60)
    for split_type, metrics in results.items():
        print(f"\n{split_type.upper()}:")
        print(f"  MSE:  {metrics[:, 0].mean():.4f} ± {metrics[:, 0].std():.4f}")
        print(f"  MAE:  {metrics[:, 1].mean():.4f} ± {metrics[:, 1].std():.4f}")
        print(f"  RMSE: {metrics[:, 2].mean():.4f} ± {metrics[:, 2].std():.4f}")